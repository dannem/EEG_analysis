{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20, 100, 100, 564)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "loaded = np.load('C:\\\\Users\\\\danne\\\\Documents\\\\UofT\\\\Discrimination\\\\time_perc.npz')\n",
    "temp = loaded['results']\n",
    "temp = np.squeeze(np.nanmean(temp, axis=1))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = np.nanmean(temp,axis=0)[:25,:25,:]\n",
    "b = np.nanmean(temp,axis=0)[25:50,25:50,:]\n",
    "a = np.squeeze(np.nanmean(a,axis=(0,1)))\n",
    "b = np.squeeze(np.nanmean(b,axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19697ab9fc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(211)\n",
    "plt.plot(np.linspace(-100,1001,564), np.squeeze(a), label='unfamiliar')\n",
    "plt.plot(np.linspace(-100,1001,564), np.squeeze(b), label='famous')\n",
    "plt.xlim((-100, 1000))\n",
    "plt.ylabel('Euclidean distance', fontsize=12)\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discr_inverted as di\n",
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.01,45)\n",
    "subs = [2]\n",
    "np.random.seed(10)\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 11  # number of pseudo-trials\n",
    "results = di.compute_combined(infolder, subs, filt, im_times, event_ids, n_perm, n_pseudo)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing compressed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danne\\Anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369685</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.455236</td>\n",
       "      <td>0.414388</td>\n",
       "      <td>0.456362</td>\n",
       "      <td>0.458469</td>\n",
       "      <td>0.474345</td>\n",
       "      <td>0.409874</td>\n",
       "      <td>0.437071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644610</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>0.619380</td>\n",
       "      <td>0.611177</td>\n",
       "      <td>0.616011</td>\n",
       "      <td>0.638521</td>\n",
       "      <td>0.621384</td>\n",
       "      <td>0.648751</td>\n",
       "      <td>0.654416</td>\n",
       "      <td>0.645167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383191</td>\n",
       "      <td>0.396159</td>\n",
       "      <td>0.414168</td>\n",
       "      <td>0.436088</td>\n",
       "      <td>0.440137</td>\n",
       "      <td>0.450841</td>\n",
       "      <td>0.378934</td>\n",
       "      <td>0.391149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>0.592378</td>\n",
       "      <td>0.596091</td>\n",
       "      <td>0.587946</td>\n",
       "      <td>0.589196</td>\n",
       "      <td>0.611327</td>\n",
       "      <td>0.602493</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.618518</td>\n",
       "      <td>0.629415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408048</td>\n",
       "      <td>0.422170</td>\n",
       "      <td>0.448836</td>\n",
       "      <td>0.432905</td>\n",
       "      <td>0.450176</td>\n",
       "      <td>0.400993</td>\n",
       "      <td>0.410474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638146</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.619090</td>\n",
       "      <td>0.609959</td>\n",
       "      <td>0.600963</td>\n",
       "      <td>0.624342</td>\n",
       "      <td>0.623935</td>\n",
       "      <td>0.647649</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.637426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.438722</td>\n",
       "      <td>0.436563</td>\n",
       "      <td>0.446202</td>\n",
       "      <td>0.465324</td>\n",
       "      <td>0.400912</td>\n",
       "      <td>0.400037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621273</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.612634</td>\n",
       "      <td>0.603743</td>\n",
       "      <td>0.593616</td>\n",
       "      <td>0.624306</td>\n",
       "      <td>0.622250</td>\n",
       "      <td>0.638010</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.618914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365545</td>\n",
       "      <td>0.404565</td>\n",
       "      <td>0.411473</td>\n",
       "      <td>0.361072</td>\n",
       "      <td>0.402807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582509</td>\n",
       "      <td>0.547162</td>\n",
       "      <td>0.541418</td>\n",
       "      <td>0.554009</td>\n",
       "      <td>0.540979</td>\n",
       "      <td>0.555893</td>\n",
       "      <td>0.553383</td>\n",
       "      <td>0.554396</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.571885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276154</td>\n",
       "      <td>0.265639</td>\n",
       "      <td>0.295465</td>\n",
       "      <td>0.292698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233880</td>\n",
       "      <td>0.260473</td>\n",
       "      <td>0.274870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220480</td>\n",
       "      <td>0.240336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  NaN  0.369685  0.400576  0.455236  0.414388  0.456362  0.458469  0.474345   \n",
       "1  NaN       NaN  0.383191  0.396159  0.414168  0.436088  0.440137  0.450841   \n",
       "2  NaN       NaN       NaN  0.408048  0.422170  0.448836  0.432905  0.450176   \n",
       "3  NaN       NaN       NaN       NaN  0.438722  0.436563  0.446202  0.465324   \n",
       "4  NaN       NaN       NaN       NaN       NaN  0.365545  0.404565  0.411473   \n",
       "..  ..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "96 NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "97 NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "98 NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "99 NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          8         9   ...        90        91        92        93        94  \\\n",
       "0   0.409874  0.437071  ...  0.644610  0.619243  0.619380  0.611177  0.616011   \n",
       "1   0.378934  0.391149  ...  0.620916  0.592378  0.596091  0.587946  0.589196   \n",
       "2   0.400993  0.410474  ...  0.638146  0.617627  0.619090  0.609959  0.600963   \n",
       "3   0.400912  0.400037  ...  0.621273  0.604500  0.612634  0.603743  0.593616   \n",
       "4   0.361072  0.402807  ...  0.582509  0.547162  0.541418  0.554009  0.540979   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "95       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "96       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "97       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "98       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "99       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          95        96        97        98        99  \n",
       "0   0.638521  0.621384  0.648751  0.654416  0.645167  \n",
       "1   0.611327  0.602493  0.620123  0.618518  0.629415  \n",
       "2   0.624342  0.623935  0.647649  0.641124  0.637426  \n",
       "3   0.624306  0.622250  0.638010  0.626023  0.618914  \n",
       "4   0.555893  0.553383  0.554396  0.564226  0.571885  \n",
       "..       ...       ...       ...       ...       ...  \n",
       "95       NaN  0.276154  0.265639  0.295465  0.292698  \n",
       "96       NaN       NaN  0.233880  0.260473  0.274870  \n",
       "97       NaN       NaN       NaN  0.220480  0.240336  \n",
       "98       NaN       NaN       NaN       NaN  0.242490  \n",
       "99       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "loaded = np.load('pearson_no_cv.npz')\n",
    "temp = loaded['result_ec']\n",
    "temp = np.nanmean(temp, axis=(0,1))\n",
    "a = pd.DataFrame(temp)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 20, 100, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "loaded = np.load('pearson_no_cv.npz')\n",
    "temp = loaded['result_ec']\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loaded = np.load('temp.npz')\n",
    "temp = loaded['results']\n",
    "temp = np.nanmean(temp, axis=1)\n",
    "temp.shape\n",
    "for i in range(temp.shape[0]):\n",
    "    print(np.nanmean(temp[i,:25,:25]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loaded = np.load('temp.npz')\n",
    "temp1 = loaded['results']\n",
    "loaded = np.load('temp2.npz')\n",
    "temp3 = loaded['results']\n",
    "loaded = np.load('temp1.npz')\n",
    "temp2 = loaded['results']\n",
    "combine_data = np.concatenate((temp1, temp2, temp3), axis=0)\n",
    "combine_data.shape\n",
    "np.savez_compressed('combined',results=combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loaded = np.load('temp.npz')\n",
    "temp = loaded['results']\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discr_inverted as di\n",
    "import numpy as np\n",
    "infolder = '/psyhome6/nemrodov/ilya_study/Data'\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.03,40)\n",
    "subs = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "np.random.seed(10)\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 12  # number of pseudo-trials\n",
    "results = di.compute_time(infolder, subs, filt, im_times, event_ids, n_perm, n_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run general_tools.ipynb\n",
    "import\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.03,200)\n",
    "subs = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "subs = [18]\n",
    "np.random.seed(10)\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 11  # number of pseudo-trials\n",
    "results = compute_time(infolder, subs, filt, im_times, event_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [--------------------] 0.0%\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_02_S01.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3385855  =      0.000 ...  6612.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 2e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.03, 200.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "2500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2500 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_02_S02.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 2043391  =      0.000 ...  3990.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 2e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.03, 200.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "1519 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 1519 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "3819 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 bad epochs dropped\n",
      "Dropped 219 epochs\n",
      "\tPermutation 1 / 20\n",
      "\tPermutation 2 / 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-431bff71a7f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m                             \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXpseudo_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind_pseudo_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                             \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                             \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_pseudo_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                             \u001b[1;31m# 4. Compute and store classification accuracies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "%run make_features.ipynb\n",
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "np.random.seed(10)\n",
    "\n",
    "pick_ch=['P9','P7','P5','P3','PO7','PO3','O1','P10','P8','P6','P4','PO8','PO4','O2','POz','Pz']\n",
    "#pick_ch=['PO8','PO7']\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.03,200)\n",
    "subs = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "subs = [2]\n",
    "\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 11  # number of pseudo-trials\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "CV = ShuffleBinLeaveOneOut\n",
    "\n",
    "out = list()\n",
    "for i,sub in enumerate(subs):\n",
    "    update_progress(i/len(subs))\n",
    "    fnames = [infolder+'\\\\IR_'+str(sub).zfill(2)+'_S01.bdf',infolder+'\\\\IR_'+str(sub).zfill(2)+'_S02.bdf']\n",
    "    epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "    epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, 2]\n",
    "    y = [a-101 if a<200 else a-151 for a in y]\n",
    "    n_conditions = len(np.unique(y))\n",
    "    n_sensors = X.shape[1]\n",
    "    n_time = X.shape[2]\n",
    "    cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "    result = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "    for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "                print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "                # 1. Compute pseudo-trials for training and test\n",
    "                Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "                Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "                for i, ind in enumerate(train_indices):\n",
    "                    Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "                for i, ind in enumerate(test_indices):\n",
    "                    Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "                # 2. Whitening using the Epoch method\n",
    "                sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "                sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                for k,c in enumerate(np.unique(y)):\n",
    "                    # compute sigma for each time point, then average across time\n",
    "                    sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                         for t in range(n_time)], axis=0)\n",
    "                sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "                sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "                Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "                Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "                for c1 in range(n_conditions-1):\n",
    "                    for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                            # 3. Fit the classifier using training data\n",
    "                            data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, :]\n",
    "                            data_train = np.reshape(data_train, (data_train.shape[0], data_train.shape[1]*data_train.shape[2]), order='F')\n",
    "                            svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                            # 4. Compute and store classification accuracies\n",
    "                            data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, :]\n",
    "                            data_test = np.reshape(data_test, (data_test.shape[0], data_test.shape[1]*data_test.shape[2]), order='F')\n",
    "                            result[f, c1, c2] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                            \n",
    "\n",
    "        # average across permutations\n",
    "    out.append(result)\n",
    "    from scipy.spatial.distance import squareform\n",
    "    a = np.nanmean(result,axis=0)[:50,:50]\n",
    "    np.nanmean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [###################-] 94.1%\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_18_S01.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3393023  =      0.000 ...  6626.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.01, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "2500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2500 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_18_S02.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3389951  =      0.000 ...  6620.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.01, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "2500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2500 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "4800 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 bad epochs dropped\n",
      "Dropped 0 epochs\n",
      "\tPermutation 1 / 20\n",
      "\tPermutation 2 / 20\n",
      "\tPermutation 3 / 20\n",
      "\tPermutation 4 / 20\n",
      "\tPermutation 5 / 20\n",
      "\tPermutation 6 / 20\n",
      "\tPermutation 7 / 20\n",
      "\tPermutation 8 / 20\n",
      "\tPermutation 9 / 20\n",
      "\tPermutation 10 / 20\n",
      "\tPermutation 11 / 20\n",
      "\tPermutation 12 / 20\n",
      "\tPermutation 13 / 20\n",
      "\tPermutation 14 / 20\n",
      "\tPermutation 15 / 20\n",
      "\tPermutation 16 / 20\n",
      "\tPermutation 17 / 20\n",
      "\tPermutation 18 / 20\n",
      "\tPermutation 19 / 20\n",
      "\tPermutation 20 / 20\n"
     ]
    }
   ],
   "source": [
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "import mne\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "from sklearn.svm import SVC\n",
    "from dissimilarity import Euclidean2, CvEuclidean2, Pearson, CvPearson\n",
    "from cv import ShuffleBinLeaveOneOut, ShuffleBin\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.01,45)\n",
    "subs = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "\n",
    "n_perm = 20  # number of permutations\n",
    "\n",
    "ec = Euclidean2()\n",
    "ec_cv = CvEuclidean2()\n",
    "ps = Pearson()\n",
    "ps_cv = CvPearson()\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "out = list()\n",
    "for i,sub in enumerate(subs):\n",
    "    if i==0:\n",
    "        n_pseudo = 11\n",
    "    else: \n",
    "        n_pseudo = 12\n",
    "        \n",
    "    update_progress(i/len(subs))\n",
    "    fnames = [infolder+'\\\\IR_'+str(sub).zfill(2)+'_S01.bdf',infolder+'\\\\IR_'+str(sub).zfill(2)+'_S02.bdf']\n",
    "    epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "    epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, 2]\n",
    "    y = [a-101 if a<200 else a-151 for a in y]\n",
    "    cv = ShuffleBin(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "    n_conditions = len(np.unique(y))\n",
    "    n_sensors = X.shape[1]\n",
    "    n_time = X.shape[2]\n",
    "    result = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "    for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "        print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "        # 1. Compute pseudo-trials for training and test\n",
    "        Xpseudo = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "        for i, ind in enumerate(test_indices):\n",
    "            Xpseudo[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "                \n",
    "\n",
    "\n",
    "        # 2. Whitening using the Epoch method\n",
    "        sigma_conditions = cv.labels_pseudo_test[0, :, n_pseudo:].flatten()\n",
    "        sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                \n",
    "        for c in range(n_conditions):\n",
    "        # compute sigma for each time point, then average across time\n",
    "            sigma_[c] = np.mean([_cov(Xpseudo[sigma_conditions==c, :, t], shrinkage='auto') for t in range(n_time)], axis=0)\n",
    "        sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "        sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "        Xpseudo = (Xpseudo.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "        for c1 in range(n_conditions-1):\n",
    "            for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):                            \n",
    "                    data = Xpseudo[cv.ind_pseudo_test[c1, c2], :, :]\n",
    "                    data = np.reshape(data, (data.shape[0], data.shape[1]*data.shape[2]), order='F')\n",
    "                    result[f, c1, c2] = ps.predict(data, y=cv.labels_pseudo_test[c1, c2])\n",
    "    out.append(result)\n",
    "np.savez_compressed('pearson_no_cv',results=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################--] 88.2%\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_17_S01.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3389439  =      0.000 ...  6619.998 secs...\n"
     ]
    }
   ],
   "source": [
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "import mne\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "from sklearn.svm import SVC\n",
    "from dissimilarity import Euclidean2, CvEuclidean2, Pearson, CvPearson\n",
    "from cv import ShuffleBinLeaveOneOut, ShuffleBin\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.01,45)\n",
    "subs = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "\n",
    "n_perm = 20  # number of permutations\n",
    "\n",
    "ec = Euclidean2()\n",
    "ec_cv = CvEuclidean2()\n",
    "ps = Pearson()\n",
    "ps_cv = CvPearson()\n",
    "CV = ShuffleBinLeaveOneOut\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "out_ec = list()\n",
    "out_pc = list()\n",
    "for i,sub in enumerate(subs):\n",
    "    if i==0:\n",
    "        n_pseudo = 11\n",
    "    else: \n",
    "        n_pseudo = 12\n",
    "        \n",
    "    update_progress(i/len(subs))\n",
    "    fnames = [infolder+'\\\\IR_'+str(sub).zfill(2)+'_S01.bdf',infolder+'\\\\IR_'+str(sub).zfill(2)+'_S02.bdf']\n",
    "    epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "    epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, 2]\n",
    "    y = [a-101 if a<200 else a-151 for a in y]\n",
    "    cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "    n_conditions = len(np.unique(y))\n",
    "    n_sensors = X.shape[1]\n",
    "    n_time = X.shape[2]\n",
    "    result_ec = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "    result_ps = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "    for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "        print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "        # 1. Compute pseudo-trials for training and test\n",
    "        Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "        Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "        for i, ind in enumerate(train_indices):\n",
    "            Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "        for i, ind in enumerate(test_indices):\n",
    "            Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "        # 2. Whitening using the Epoch method\n",
    "        sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "        sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "        for k,c in enumerate(np.unique(y)):\n",
    "            # compute sigma for each time point, then average across time\n",
    "            sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                         for t in range(n_time)], axis=0)\n",
    "        sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "        sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "        Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "        Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "        for c1 in range(n_conditions-1):\n",
    "            for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):                        \n",
    "                data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, :]\n",
    "                data_train = np.reshape(data_train, (data_train.shape[0], data_train.shape[1]*data_train.shape[2]), order='F')\n",
    "                ec_cv.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "                ps_cv.fit(data_train, cv.labels_pseudo_train[c1, c2])\n",
    "                \n",
    "                data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, :] \n",
    "                data_test = np.reshape(data_test, (data_test.shape[0], data_test.shape[1]*data_test.shape[2]), order='F')\n",
    "                \n",
    "                result_ec[f, c1, c2] = ec_cv.predict(data_test, y=cv.labels_pseudo_test[c1, c2])\n",
    "                result_ps[f, c1, c2] = ps_cv.predict(data_test, y=cv.labels_pseudo_test[c1, c2])\n",
    "    out_ec.append(result_ec)\n",
    "    out_pc.append(result_ps)\n",
    "np.savez_compressed('distance_with_cv',result_ec=out_ec, result_pc=out_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 36096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dissimilarity import Euclidean2, CvEuclidean2, Pearson, CvPearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('acc_perc_all',results=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = list()\n",
    "out.append(result)\n",
    "for i in results:\n",
    "    out.append(i)\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 100, 100, 564)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "loaded = np.load('temp_11.npz')\n",
    "results = loaded['results']\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out:\n",
    "    print(np.nanmean(i[:,:25,:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "%run make_features.ipynb\n",
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "np.random.seed(10)\n",
    "\n",
    "pick_ch=['P9','P7','P5','P3','PO7','PO3','O1','P10','P8','P6','P4','PO8','PO4','O2','POz','Pz']\n",
    "#pick_ch=['PO8','PO7']\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.03,200)\n",
    "fnames = ['E:\\\\Ilya_study\\\\Data\\\\IR_06_S01.bdf','E:\\\\Ilya_study\\\\Data\\\\IR_06_S02.bdf']\n",
    "epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "#epochs = block_average(epochs,4,12, kind='perc',zscore = False)\n",
    "pick_ch = mne.pick_channels(epochs.ch_names, pick_ch)\n",
    "#data = epochs.get_data()[:, pick_ch, :]\n",
    "X = epochs.get_data()\n",
    "y = epochs.events[:, 2]\n",
    "y = [a-101 if a<200 else a-151 for a in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Parameters\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 12  # number of pseudo-trials\n",
    "n_conditions = len(np.unique(y))\n",
    "n_sensors = X.shape[1]\n",
    "n_time = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "CV = ShuffleBinLeaveOneOut\n",
    "cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "result = np.full((n_perm, n_conditions, n_conditions, n_time), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "            print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "            # 1. Compute pseudo-trials for training and test\n",
    "            Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "            Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "            for i, ind in enumerate(train_indices):\n",
    "                Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "            for i, ind in enumerate(test_indices):\n",
    "                Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "            # 2. Whitening using the Epoch method\n",
    "            sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "            sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "            for k,c in enumerate(np.unique(y)):\n",
    "                # compute sigma for each time point, then average across time\n",
    "                sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                     for t in range(n_time)], axis=0)\n",
    "            sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "            sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "            Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "            Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "            for t in range(n_time):\n",
    "                for c1 in range(n_conditions-1):\n",
    "                    for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                            # 3. Fit the classifier using training data\n",
    "                            data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, t]\n",
    "                            svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                            # 4. Compute and store classification accuracies\n",
    "                            data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, t]\n",
    "                            result[f, c1, c2, t] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                            \n",
    "                           \n",
    "    # average across permutations\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( 'cum_accuracy_06.npy', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load('C:\\\\Users\\\\danne\\\\Documents\\Codes\\\\EEG_analysis\\\\result_decoding_time.npy')\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load('C:\\\\Users\\\\danne\\\\Documents\\Codes\\\\EEG_analysis\\\\result_decoding_time.npy')\n",
    "temp1 = np.nanmean(temp[:,:25,:25,:], axis=(0,1,2))\n",
    "temp2 = np.nanmean(temp[:,25:50,25:50,:], axis=(0,1,2))\n",
    "temp.shape\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.linspace(-100,1000,564),temp1, label='unfamiliar')\n",
    "plt.plot(np.linspace(-100,1000,564),temp2, label='famous')\n",
    "plt.legend()\n",
    "plt.savefig('sub6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "            print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "            # 1. Compute pseudo-trials for training and test\n",
    "            Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "            Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "            for i, ind in enumerate(train_indices):\n",
    "                Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "            for i, ind in enumerate(test_indices):\n",
    "                Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "            # 2. Whitening using the Epoch method\n",
    "            sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "            sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "            for k,c in enumerate(np.unique(y)):\n",
    "                # compute sigma for each time point, then average across time\n",
    "                sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                     for t in range(n_time)], axis=0)\n",
    "            sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "            sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "            Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "            Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "            for c1 in range(n_conditions-1):\n",
    "                for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                        # 3. Fit the classifier using training data\n",
    "                        data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, :]\n",
    "                        data_train = np.reshape(data_train, (data_train.shape[0], data_train.shape[1]*data_train.shape[2]), order='F')\n",
    "                        svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                        # 4. Compute and store classification accuracies\n",
    "                        data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, :]\n",
    "                        data_test = np.reshape(data_test, (data_test.shape[0], data_test.shape[1]*data_test.shape[2]), order='F')\n",
    "                        result[f, c1, c2] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                            \n",
    "                           \n",
    "    # average across permutations\n",
    "from scipy.spatial.distance import squareform\n",
    "a = np.nanmean(result,axis=0)[:50,:50]\n",
    "np.nanmean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(result[7,:10,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a seed, in order to make analyses reproducible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '' # This is the /path/to the directory containing the data.\n",
    "          # We leave it empty here, because the data is located in the current directory.\n",
    "\n",
    "# Load data and trial labels for the two sessions of participant 01\n",
    "sessions = [\n",
    "    # Session 1\n",
    "    dict(\n",
    "        data=np.load(os.path.join(root, 'data01_sess1.npy')),\n",
    "        # data has shape n_trials x n_sensors x n_timepoints\n",
    "        labels=np.load(os.path.join(root, 'labels01_sess1.npy'))\n",
    "        # labels has shape 1 x n_trials (i.e., one condition label [object category] per trial)\n",
    "    ),\n",
    "    # Session 2\n",
    "    dict(\n",
    "        data=np.load(os.path.join(root, 'data01_sess2.npy')),\n",
    "        labels=np.load(os.path.join(root, 'labels01_sess2.npy'))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set some parameters. Only the number of permutations and the number of pseudo-trials are free parameters. The number of conditions, sensors, time points and sessions are derived from the data (i.e., from the `sessions` variable above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_sessions = len(sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define three classifiers that will be compared: Support Vector Machine, Gaussian Naive Bayes and the [Weighted Robust Distance](https://github.com/m-guggenmos/weird). We provide the code for Linear Discriminant Analysis only in comments, as it is quite slow in this scikit-learn Python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gnb = GaussianNB()\n",
    "weird = WeiRD()\n",
    "# lda = LDA(sigma=np.eye(n_sensors))  # passing identitity covariance matrix to LDA, since data is pre-whitened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose our partitioning scheme, here `ShuffleBinLeaveOneOut`. This class will provide the trial-to-pseudo-trial assignments for each permutation. We'll define the class object already at this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose data partitioning scheme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytic logic is contained in a nested for loop, with loops for the number of sessions, number of permutations, number of timepoints, number of conditions, and number of conditions again. Overall, the logic contains 4 crucial steps:\n",
    "1. Compute pseudo-trials for the training and test data\n",
    "2. Whiten the training data (here using the Epoch method, which is recommended in our manuscript)\n",
    "3. Fit the classifier to the training data\n",
    "4. Compute classification accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-load mechanism, for convenience\n",
    "preload_result = True # for recomputing the decoding analyses, set to False\n",
    "if preload_result:\n",
    "    result = np.load(os.path.join(root, 'result_decoding.npy'))\n",
    "else:\n",
    "    result = np.full((n_sessions, n_perm, n_conditions, n_conditions, n_time), np.nan,\n",
    "                     dtype={'names': ['svm', 'gnb', 'weird', 'lda'], 'formats': 4*['f8']})\n",
    "\n",
    "    for s, session in enumerate(sessions):\n",
    "\n",
    "        print('Session %g / %g' % (s + 1, n_sessions))\n",
    "\n",
    "        X = session['data']\n",
    "        y = session['labels']\n",
    "\n",
    "        cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "\n",
    "        for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "            print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "            # 1. Compute pseudo-trials for training and test\n",
    "            Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "            Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "            for i, ind in enumerate(train_indices):\n",
    "                Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "            for i, ind in enumerate(test_indices):\n",
    "                Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "            # 2. Whitening using the Epoch method\n",
    "            sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "            sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "            for c in range(n_conditions):\n",
    "                # compute sigma for each time point, then average across time\n",
    "                sigma_[c] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                     for t in range(n_time)], axis=0)\n",
    "            sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "            sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "            Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "            Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "            for t in range(n_time):\n",
    "                for c1 in range(n_conditions-1):\n",
    "                    for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                            # 3. Fit the classifier using training data\n",
    "                            data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, t]\n",
    "                            svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "                            gnb.fit(data_train, cv.labels_pseudo_train[c1, c2])\n",
    "                            weird.fit(data_train, cv.labels_pseudo_train[c1, c2])\n",
    "                            # lda.fit(data_train, cv.labels_pseudo_train[c1, c2])\n",
    "\n",
    "                            # 4. Compute and store classification accuracies\n",
    "                            data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, t]\n",
    "                            result['svm'][s, f, c1, c2, t] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                            \n",
    "                            result['gnb'][s, f, c1, c2, t] = np.mean(gnb.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5\n",
    "                            result['weird'][s, f, c1, c2, t] = np.mean(weird.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5\n",
    "                            # result['lda'][s, f, c1, c2, t] = np.mean(lda.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5\n",
    "    # average across permutations\n",
    "    result_ = np.full((n_sessions, n_conditions, n_conditions, n_time), np.nan,\n",
    "                      dtype={'names': ['svm', 'gnb', 'weird', 'lda'], 'formats': 4*['f8']})    \n",
    "    result_['svm'] = np.nanmean(result['svm'], axis=1)\n",
    "    result_['gnb'] = np.nanmean(result['gnb'], axis=1)\n",
    "    result_['weird'] = np.nanmean(result['weird'], axis=1)\n",
    "    # result_['lda'] = np.nanmean(result['lda'], axis=1)\n",
    "    result = result_\n",
    "    np.save(os.path.join(root, 'result_decoding.npy'), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the average classification accuracy time course by collapsing across sessions and conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(-100, 1001, 10), 100*np.nanmean(result['svm'], axis=(0, 1, 2))+50, label='SVM')\n",
    "plt.plot(np.arange(-100, 1001, 10), 100*np.nanmean(result['gnb'], axis=(0, 1, 2))+50, label='GNB')\n",
    "plt.plot(np.arange(-100, 1001, 10), 100*np.nanmean(result['weird'], axis=(0, 1, 2))+50, label='WeiRD')\n",
    "if 'lda' in result.dtype.names:\n",
    "    plt.plot(np.arange(-100, 1001, 10), 100*np.nanmean(result['lda'], axis=(0, 1, 2))+50, label='LDA')\n",
    "plt.plot([-100, 1000], [50, 50], 'k-')\n",
    "plt.xlim((-100, 1000))\n",
    "plt.xlabel('Time [ms]', fontsize=15)\n",
    "plt.ylabel('Classification accuracy', fontsize=15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corellation of new accuracies with old accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danne\\Anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.05965992795586425, 0.036813566889765156)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.stats import pearsonr\n",
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "data = load_pkl(outfolder, 'svm_prc_accuracy.pkl')\n",
    "data_old = np.squeeze(np.array(data))\n",
    "data_old = squareform(data_old[:50,:50])\n",
    "\n",
    "loaded = np.load('E:\\\\Ilya_study\\\\Confusion matrices\\\\combined.npz')\n",
    "temp = loaded['results']\n",
    "temp = np.nanmean(temp, axis=(0,1))\n",
    "data_new = np.squeeze(squareform(squareform(temp, checks=False)))\n",
    "data_new = squareform(data_new[:50,:50])\n",
    "\n",
    "out = pearsonr(data_old,data_new)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of new accuracies with theoeretical observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danne\\Anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02759494449790384, 0.3345343810704185)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.stats import pearsonr\n",
    "%run general_tools.ipynb\n",
    "%run EEG_auxiliary_module.ipynb\n",
    "\n",
    "\n",
    "stims = pd.read_csv('C:\\\\Users\\\\danne\\\\Dropbox\\\\Ilya_study\\\\Stimuli\\\\stims.csv')\n",
    "descr = pd.read_csv('C:\\\\Users\\\\danne\\\\Dropbox\\\\Ilya_study\\\\Analysis\\\\description.csv', index_col = 'Nums') # loading origin desription\n",
    "dist = pdist(stims.T)\n",
    "\n",
    "loaded = np.load('E:\\\\Ilya_study\\\\Confusion matrices\\\\combined.npz')\n",
    "temp = loaded['results']\n",
    "temp = np.nanmean(temp, axis=(0,1))\n",
    "data_new = np.squeeze(squareform(squareform(temp, checks=False)))\n",
    "data_new = squareform(data_new[:50,:50])\n",
    "\n",
    "out = pearsonr(dist,data_new)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of old accuracies with TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01450476444235551, 0.6120319194925341)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pearsonr(dist,data_old)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between participants in new results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Ilya_study\\\\Analysis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagery analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
