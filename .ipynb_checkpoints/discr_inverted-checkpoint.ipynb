{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product, combinations\n",
    "from scipy.special import binom\n",
    "\n",
    "class ValidationSplit():\n",
    "    def __init__(self, labels_train, labels_test):\n",
    "\n",
    "        self.labels_train = labels_train\n",
    "        self.labels_test = labels_test\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield np.arange(len(self.labels_train)), \\\n",
    "              np.arange(len(self.labels_train), len(self.labels_train) + len(self.labels_test))\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return 1\n",
    "\n",
    "\n",
    "class ShuffleBinLeaveOneOut:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_train = np.full((self.n_classes, self.n_classes, 2*(self.n_pseudo-1)),\n",
    "                                        np.nan, dtype=np.int)\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, self.n_classes, 2), np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_train = np.full((self.n_classes, self.n_classes, 2*(self.n_pseudo-1)),\n",
    "                                           np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, self.n_classes, 2), np.nan, dtype=np.int)\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*(self.n_pseudo-1), (c1+1)*(self.n_pseudo-1))\n",
    "            for c2 in range(self.n_classes):\n",
    "                range_c2 = range(c2*(self.n_pseudo-1), (c2+1)*(self.n_pseudo-1))\n",
    "                self.ind_pseudo_train[c1, c2, :2*(self.n_pseudo - 1)] = \\\n",
    "                    np.concatenate((range_c1, range_c2))\n",
    "                self.ind_pseudo_test[c1, c2] = [c1, c2]\n",
    "\n",
    "                self.labels_pseudo_train[c1, c2, :2*(self.n_pseudo - 1)] = \\\n",
    "                    np.concatenate((self.classes[c1] * np.ones(self.n_pseudo - 1),\n",
    "                                    self.classes[c2] * np.ones(self.n_pseudo - 1)))\n",
    "                self.labels_pseudo_test[c1, c2] = self.classes[[c1, c2]].astype(self.labels_pseudo_train.dtype)\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_train = np.full(self.n_classes*(self.n_pseudo-1), np.nan, dtype=np.object)\n",
    "        _ind_test = np.full(self.n_classes, np.nan, dtype=np.object)\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(np.random.permutation(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*(self.n_pseudo-1), (c1+1)*(self.n_pseudo-1))):\n",
    "                    _ind_train[j] = ind[i]\n",
    "                _ind_test[c1] = ind[-1]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n_iter\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "class ShuffleBinLeaveOneOutWithin:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_train = np.full((self.n_classes, 1, self.n_pseudo-2),\n",
    "                                        np.nan, dtype=np.int)\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, 1, 2), np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_train = np.full((self.n_classes, 1, self.n_pseudo-2),\n",
    "                                           np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, 1, 2), np.nan, dtype=np.int)\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*(self.n_pseudo-2), (c1+1)*(self.n_pseudo-2))\n",
    "\n",
    "            self.ind_pseudo_train[c1, 0, :self.n_pseudo - 2] = range_c1\n",
    "            self.ind_pseudo_test[c1, 0] = [c1*2, c1*2+1]\n",
    "\n",
    "            self.labels_pseudo_train[c1, 0, :self.n_pseudo - 2] = self.classes[c1] * np.ones(self.n_pseudo - 2)\n",
    "            self.labels_pseudo_test[c1, 0] = self.classes[[c1, c1]].astype(self.labels_pseudo_train.dtype)\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_train = np.full(self.n_classes*(self.n_pseudo-2), np.nan, dtype=np.object)\n",
    "        _ind_test = np.full(self.n_classes*2, np.nan, dtype=np.object)\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(np.random.permutation(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*(self.n_pseudo-2), (c1+1)*(self.n_pseudo-2))):\n",
    "                    _ind_train[j] = ind[i]\n",
    "                for i, j in enumerate(range(c1*2, (c1+1)*2)):\n",
    "                    _ind_test[j] = ind[-i-1]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n_iter\n",
    "\n",
    "class ShuffleBin:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, self.n_classes, 2 * self.n_pseudo),\n",
    "                                       np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, self.n_classes, 2 * self.n_pseudo),\n",
    "                                          np.nan, dtype=np.int)\n",
    "\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)\n",
    "            for c2 in range(self.n_classes):\n",
    "                range_c2 = range(c2*self.n_pseudo, (c2+1)*self.n_pseudo)\n",
    "                self.ind_pseudo_test[c1, c2, :2 * self.n_pseudo] = np.concatenate((range_c1, range_c2))\n",
    "                self.labels_pseudo_test[c1, c2, :2 * self.n_pseudo] = \\\n",
    "                    np.concatenate((self.classes[c1] * np.ones(self.n_pseudo),\n",
    "                                    self.classes[c2] * np.ones(self.n_pseudo)))\n",
    "        self.ind_pseudo_train = []\n",
    "        self.labels_pseudo_train = []\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_test = np.full(self.n_classes*self.n_pseudo, np.nan, dtype=np.object)\n",
    "        _ind_train = []\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(np.random.permutation(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)):\n",
    "                    _ind_test[j] = ind[i]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n_iter\n",
    "\n",
    "\n",
    "class ShuffleBinTest:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, self.n_classes, 2 * self.n_pseudo),\n",
    "                                       np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, self.n_classes, 2 * self.n_pseudo),\n",
    "                                          np.nan, dtype=np.int)\n",
    "\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)\n",
    "            for c2 in range(self.n_classes):\n",
    "                range_c2 = range(c2*self.n_pseudo, (c2+1)*self.n_pseudo)\n",
    "                self.ind_pseudo_test[c1, c2, :2 * self.n_pseudo] = np.concatenate((range_c1, range_c2))\n",
    "                self.labels_pseudo_test[c1, c2, :2 * self.n_pseudo] = \\\n",
    "                    np.concatenate((self.classes[c1] * np.ones(self.n_pseudo),\n",
    "                                    self.classes[c2] * np.ones(self.n_pseudo)))\n",
    "        self.ind_pseudo_train = []\n",
    "        self.labels_pseudo_train = []\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_test = np.full(self.n_classes*self.n_pseudo, np.nan, dtype=np.object)\n",
    "        _ind_train = []\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(range(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)):\n",
    "                    _ind_test[j] = ind[i]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "    def get_n_splits(self):\n",
    "        return self.n_iter\n",
    "\n",
    "\n",
    "class ShuffleBinWithin:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, 1, self.n_pseudo),\n",
    "                                       np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, 1, self.n_pseudo),\n",
    "                                          np.nan, dtype=np.int)\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)\n",
    "\n",
    "            self.ind_pseudo_test[c1, 0, :self.n_pseudo] = range_c1\n",
    "            self.labels_pseudo_test[c1, 0, :self.n_pseudo] = self.classes[c1] * np.ones(self.n_pseudo)\n",
    "        self.ind_pseudo_train = []\n",
    "        self.labels_pseudo_train = []\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_test = np.full(self.n_classes*self.n_pseudo, np.nan, dtype=np.object)\n",
    "        _ind_train = []\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(np.random.permutation(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)):\n",
    "                    _ind_test[j] = ind[i]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n_iter\n",
    "\n",
    "\n",
    "class ShuffleBinWithinTest:\n",
    "\n",
    "    def __init__(self, labels, n_iter=10, n_pseudo=5):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List<int>, np.ndarray()\n",
    "            Label for each trial\n",
    "        n_iter : int\n",
    "            Number of permutations\n",
    "        n_pseudo : int\n",
    "            How many trials belong to one bin (aka pseudo-trial)\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = np.array(labels)\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.classes, self.n_trials = np.unique(labels, return_counts=True)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_pseudo = n_pseudo\n",
    "        self._compute_pseudo_info()\n",
    "\n",
    "    def _compute_pseudo_info(self):\n",
    "        \"\"\"\n",
    "        Compute indices and labels for the pseudo-trial matrix\n",
    "        The pseudo-trial matrix is the resulting matrix *after* having grouped the data into\n",
    "        randomly permuted pseudo-trial bins and averaging trials within each bin. Thus, no\n",
    "        additional permutation is necessary for pseudo-trial indices, which are somewhat trivial.\n",
    "        \"\"\"\n",
    "        self.ind_pseudo_test = np.full((self.n_classes, 1, self.n_pseudo),\n",
    "                                       np.nan, dtype=np.int)\n",
    "        self.labels_pseudo_test = np.full((self.n_classes, 1, self.n_pseudo),\n",
    "                                          np.nan, dtype=np.int)\n",
    "        for c1 in range(self.n_classes):\n",
    "            range_c1 = range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)\n",
    "\n",
    "            self.ind_pseudo_test[c1, 0, :self.n_pseudo] = range_c1\n",
    "            self.labels_pseudo_test[c1, 0, :self.n_pseudo] = self.classes[c1] * np.ones(self.n_pseudo)\n",
    "        self.ind_pseudo_train = []\n",
    "        self.labels_pseudo_train = []\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generator function for the cross-validation object. Each fold corresponds to a new random\n",
    "        grouping of trials into pseudo-trials.\n",
    "        \"\"\"\n",
    "        _ind_test = np.full(self.n_classes*self.n_pseudo, np.nan, dtype=np.object)\n",
    "        _ind_train = []\n",
    "        for perm in range(self.n_iter):\n",
    "            for c1 in range(self.n_classes):  # separate permutation for each class\n",
    "                prm = np.array(np.array_split(range(self.n_trials[c1]), self.n_pseudo))\n",
    "                ind = prm + np.sum(self.n_trials[:c1])\n",
    "                for i, j in enumerate(range(c1*self.n_pseudo, (c1+1)*self.n_pseudo)):\n",
    "                    _ind_test[j] = ind[i]\n",
    "            yield _ind_train, _ind_test\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_iter\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n_iter\n",
    "\n",
    "class XClassSplit():\n",
    "\n",
    "    def __init__(self, runs, sets):\n",
    "        self.sets = np.atleast_2d(sets)\n",
    "        self.runs = np.array(runs, dtype=np.int)\n",
    "\n",
    "        self.unique_runs = np.unique(self.runs)\n",
    "        self.unique_sets = np.atleast_2d([np.unique(s) for s in self.sets])\n",
    "        self.n = sum([len(s) * len(self.unique_runs) for s in self.unique_sets])\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for s, set in enumerate(self.sets):\n",
    "            for set_id in self.unique_sets[s]:\n",
    "                for run in self.unique_runs:\n",
    "                    test_index = np.where((set == set_id) & (self.runs == run))[0]\n",
    "                    train_index = np.where((set != set_id) & (self.runs != run))[0]\n",
    "                    yield train_index, test_index\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None):\n",
    "        return self.n\n",
    "\n",
    "\n",
    "# class ExhaustiveLeave2Out:\n",
    "#\n",
    "#     def __init__(self, labels):\n",
    "#         self.labels = labels\n",
    "#         self.classes = np.unique(self.labels)\n",
    "#         self.n_samples = len(self.labels)\n",
    "#         n_samples1 = np.sum(self.labels == self.classes[0])\n",
    "#         n_samples2 = np.sum(self.labels == self.classes[1])\n",
    "#         self.n_iter = 2 * n_samples1 * n_samples2\n",
    "#\n",
    "#     def __iter__(self):\n",
    "#         for i, l in enumerate(self.labels):\n",
    "#             other_class = self.classes[0] if l == self.classes[1] else self.classes[1]\n",
    "#             ind_other_class = np.where(self.labels == other_class)[0]\n",
    "#             for i in ind_other_class:\n",
    "#                 test_ind = [i, i]\n",
    "#                 train_ind = np.setdiff1d(range(self.n_samples), test_ind)\n",
    "#                 yield train_ind, test_ind\n",
    "#\n",
    "#     def split(self, X, y=None):\n",
    "#         return self.__iter__()\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return self.n_iter\n",
    "#\n",
    "#     def get_n_splits(self):\n",
    "#         return self.n_iter\n",
    "\n",
    "\n",
    "class SuperExhaustiveLeaveNOut:\n",
    "\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __iter__(self, y):\n",
    "        for test_ind in combinations(range(len(y)), self.N):\n",
    "            train_ind = np.setdiff1d(range(len(y)), test_ind)\n",
    "            yield train_ind, np.array(test_ind)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        return self.__iter__(y)\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return int(binom(len(y), self.N))\n",
    "\n",
    "\n",
    "class ExhaustiveLeave2Out:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self, y):\n",
    "        classes = np.unique(y)\n",
    "        ind1 = np.where(y == classes[0])[0]\n",
    "        ind2 = np.where(y == classes[1])[0]\n",
    "        for test_ind in product(ind1, ind2):\n",
    "            train_ind = np.setdiff1d(range(len(y)), test_ind)\n",
    "            yield train_ind, np.array(test_ind)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        return self.__iter__(y)\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        classes = np.unique(y)\n",
    "        n_samples1 = np.sum(y == classes[0])\n",
    "        n_samples2 = np.sum(y == classes[1])\n",
    "        return n_samples1 * n_samples2\n",
    "\n",
    "\n",
    "class SubsetLeave2Out:\n",
    "\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def __iter__(self, y):\n",
    "        classes = np.unique(y)\n",
    "        ind1 = np.where(y == classes[0])[0]\n",
    "        ind2 = np.where(y == classes[1])[0]\n",
    "        combos = list(product(ind1, ind2))\n",
    "        order = np.random.choice(len(combos), self.n_splits, replace=False)\n",
    "        for i in range(self.n_splits):\n",
    "            test_ind = np.array(combos[order[i]])\n",
    "            train_ind = np.setdiff1d(range(len(y)), test_ind)\n",
    "            yield train_ind, test_ind\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        return self.__iter__(y)\n",
    "\n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "\n",
    "class ProxyCV:\n",
    "\n",
    "    def __init__(self, train_ind, test_ind):\n",
    "        self.train_ind = train_ind\n",
    "        self.test_ind = test_ind\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self.train_ind, self.test_ind\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def get_n_splits(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "class DummyCV:\n",
    "\n",
    "    def __init__(self, n_samples):\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield list(range(self.n_samples)), []\n",
    "\n",
    "    def split(self, X, y=None):\n",
    "        return self.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def get_n_splits(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined(folder, subs, filt, im_times, event_ids):\n",
    "    from pathlib import Path, PurePath\n",
    "    import numpy as np\n",
    "    import mne\n",
    "    from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "    import os\n",
    "    import scipy\n",
    "    from sklearn.discriminant_analysis import _cov\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "    svm = SVC(kernel='linear')\n",
    "    CV = ShuffleBinLeaveOneOut\n",
    "    out = list()\n",
    "    \n",
    "    for i,sub in enumerate(subs):\n",
    "        update_progress(i/len(subs))\n",
    "        fnames = [folder+'\\\\IR_'+str(sub).zfill(2)+'_S01.bdf',folder+'\\\\IR_'+str(sub).zfill(2)+'_S02.bdf']\n",
    "        epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "        epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, 2]\n",
    "        y = [a-101 if a<200 else a-151 for a in y]\n",
    "        n_conditions = len(np.unique(y))\n",
    "        n_sensors = X.shape[1]\n",
    "        n_time = X.shape[2]\n",
    "        cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "        result = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "        for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "                    print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "                    # 1. Compute pseudo-trials for training and test\n",
    "                    Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "                    Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "                    for i, ind in enumerate(train_indices):\n",
    "                        Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "                    for i, ind in enumerate(test_indices):\n",
    "                        Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "                    # 2. Whitening using the Epoch method\n",
    "                    sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "                    sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                    for k,c in enumerate(np.unique(y)):\n",
    "                        # compute sigma for each time point, then average across time\n",
    "                        sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                             for t in range(n_time)], axis=0)\n",
    "                    sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "                    sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "                    Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "                    Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "                    for c1 in range(n_conditions-1):\n",
    "                        for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                                # 3. Fit the classifier using training data\n",
    "                                data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, :]\n",
    "                                data_train = np.reshape(data_train, (data_train.shape[0], data_train.shape[1]*data_train.shape[2]), order='F')\n",
    "                                svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                                # 4. Compute and store classification accuracies\n",
    "                                data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, :]\n",
    "                                data_test = np.reshape(data_test, (data_test.shape[0], data_test.shape[1]*data_test.shape[2]), order='F')\n",
    "                                result[f, c1, c2] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                            \n",
    "\n",
    "        # average across permutations\n",
    "        out.append(result)\n",
    "        a = np.nanmean(result,axis=0)[:50,:50]\n",
    "        print(np.nanmean(a))\n",
    "        np.savez_compressed('temp',results=out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_epochs_perc(fnames, event_ids, im_times, filt):\n",
    "    import mne\n",
    "    import numpy as np\n",
    "    import os.path as op\n",
    "    from mne.channels import make_standard_montage\n",
    "    %run general_tools.ipynb\n",
    "    infolder, outfolder = find_folder()\n",
    "    baseline = (None, 0)\n",
    "    \n",
    "   \n",
    "    montage = make_standard_montage('biosemi64')\n",
    "    \n",
    "    epochs = []\n",
    "    for fname in fnames:\n",
    "        fname = op.join(infolder,fname) \n",
    "        raw = mne.io.read_raw_bdf(fname, preload=True).filter(filt[0], filt[1], method='iir')\n",
    "        raw.set_montage(montage)\n",
    "        events = mne.find_events(raw, initial_event=True, \n",
    "                                 consecutive=True, shortest_event=1, verbose=0)\n",
    "        temp = mne.Epochs(raw, events, event_ids, im_times[0], im_times[1],\n",
    "                          baseline=baseline, preload=True, detrend = 1)\n",
    "        temp = temp[100:]\n",
    "        epochs.append(temp)\n",
    "\n",
    "    epochs = mne.concatenate_epochs(epochs)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time(folder, subs, filt, im_times, event_ids):\n",
    "    from pathlib import Path, PurePath\n",
    "    import numpy as np\n",
    "    import mne\n",
    "    from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "    import os\n",
    "    import scipy\n",
    "    from sklearn.discriminant_analysis import _cov\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "    svm = SVC(kernel='linear')\n",
    "    CV = ShuffleBinLeaveOneOut\n",
    "    out = list()\n",
    "    \n",
    "    \n",
    "    for i,sub in enumerate(subs):\n",
    "        update_progress(i/len(subs))\n",
    "        fnames = [folder+'\\\\IR_'+str(sub).zfill(2)+'_S01.bdf',folder+'\\\\IR_'+str(sub).zfill(2)+'_S02.bdf']\n",
    "        epochs = load_to_epochs_perc(fnames, event_ids, im_times, filt)\n",
    "        epochs.drop_channels(['Status']).equalize_event_counts(event_ids=event_ids, method='mintime')\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, 2]\n",
    "        y = [a-101 if a<200 else a-151 for a in y]\n",
    "        n_conditions = len(np.unique(y))\n",
    "        n_sensors = X.shape[1]\n",
    "        n_time = X.shape[2]\n",
    "        cv = CV(y, n_iter=n_perm, n_pseudo=n_pseudo)\n",
    "        result = np.full((n_perm, n_conditions, n_conditions), np.nan)\n",
    "        for f, (train_indices, test_indices) in enumerate(cv.split(X)):\n",
    "                    print('\\tPermutation %g / %g' % (f + 1, n_perm))\n",
    "\n",
    "                    # 1. Compute pseudo-trials for training and test\n",
    "                    Xpseudo_train = np.full((len(train_indices), n_sensors, n_time), np.nan)\n",
    "                    Xpseudo_test = np.full((len(test_indices), n_sensors, n_time), np.nan)\n",
    "                    for i, ind in enumerate(train_indices):\n",
    "                        Xpseudo_train[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "                    for i, ind in enumerate(test_indices):\n",
    "                        Xpseudo_test[i, :, :] = np.mean(X[ind, :, :], axis=0)\n",
    "\n",
    "\n",
    "                    # 2. Whitening using the Epoch method\n",
    "                    sigma_conditions = cv.labels_pseudo_train[0, :, n_pseudo-1:].flatten()\n",
    "                    sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                    for k,c in enumerate(np.unique(y)):\n",
    "                        # compute sigma for each time point, then average across time\n",
    "                        sigma_[k] = np.mean([_cov(Xpseudo_train[sigma_conditions==c, :, t], shrinkage='auto')\n",
    "                                             for t in range(n_time)], axis=0)\n",
    "                    sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "                    sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "                    Xpseudo_train = (Xpseudo_train.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "                    Xpseudo_test = (Xpseudo_test.swapaxes(1, 2) @ sigma_inv).swapaxes(1, 2)\n",
    "\n",
    "                    for c1 in range(n_conditions-1):\n",
    "                        for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                                # 3. Fit the classifier using training data\n",
    "                                data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, :]\n",
    "                                data_train = np.reshape(data_train, (data_train.shape[0], data_train.shape[1]*data_train.shape[2]), order='F')\n",
    "                                svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                                for t in range(n_time):\n",
    "                                    for c1 in range(n_conditions-1):\n",
    "                                        for c2 in range(min(c1 + 1, n_conditions-1), n_conditions):\n",
    "                                            # 3. Fit the classifier using training data\n",
    "                                            data_train = Xpseudo_train[cv.ind_pseudo_train[c1, c2], :, t]\n",
    "                                            svm.fit(data_train, cv.labels_pseudo_train[c1, c2])                            \n",
    "\n",
    "                                            # 4. Compute and store classification accuracies\n",
    "                                            data_test = Xpseudo_test[cv.ind_pseudo_test[c1, c2], :, t]\n",
    "                                            result[f, c1, c2, t] = np.mean(svm.predict(data_test) == cv.labels_pseudo_test[c1, c2]) - 0.5                  \n",
    "\n",
    "        # average across permutations\n",
    "        out.append(result)\n",
    "        a = np.nanmean(result,axis=0)[:50,:50,:]\n",
    "        print(np.nanmean(a))\n",
    "        np.savez_compressed('temp',results=out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [--------------------] 0.0%\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_18_S01.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3393023  =      0.000 ...  6626.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 2e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.03, 200.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "2500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2500 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from E:\\Ilya_study\\Data\\IR_18_S02.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3389951  =      0.000 ...  6620.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 2e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.03, 200.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "2500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2500 events and 564 original time points ...\n",
      "0 bad epochs dropped\n",
      "4800 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 bad epochs dropped\n",
      "Dropped 0 epochs\n",
      "\tPermutation 1 / 20\n",
      "\tPermutation 2 / 20\n",
      "\tPermutation 3 / 20\n",
      "\tPermutation 4 / 20\n",
      "\tPermutation 5 / 20\n",
      "\tPermutation 6 / 20\n",
      "\tPermutation 7 / 20\n",
      "\tPermutation 8 / 20\n",
      "\tPermutation 9 / 20\n",
      "\tPermutation 10 / 20\n",
      "\tPermutation 11 / 20\n",
      "\tPermutation 12 / 20\n",
      "\tPermutation 13 / 20\n",
      "\tPermutation 14 / 20\n",
      "\tPermutation 15 / 20\n",
      "\tPermutation 16 / 20\n",
      "\tPermutation 17 / 20\n",
      "\tPermutation 18 / 20\n",
      "\tPermutation 19 / 20\n"
     ]
    }
   ],
   "source": [
    "%run general_tools.ipynb\n",
    "infolder, outfolder = find_folder()\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "#trigs=list(range(101, 151))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "im_times=(-0.1,1)\n",
    "filt=(0.03,200)\n",
    "subs = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "subs = [18]\n",
    "np.random.seed(10)\n",
    "n_perm = 20  # number of permutations\n",
    "n_pseudo = 11  # number of pseudo-trials\n",
    "results = compute_time(infolder, subs, filt, im_times, event_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    y = np.array(['r1_A1', 'r1_A2', 'r1_B1', 'r1_B2','r2_A1', 'r2_A2', 'r2_B1', 'r2_B2','r3_A1', 'r3_A2', 'r3_B1', 'r3_B2'])\n",
    "\n",
    "    sets = [[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]]\n",
    "    runs = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]\n",
    "    cv = XClassSplit(runs, sets)\n",
    "\n",
    "    for train, test in cv:\n",
    "        print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        print(\"y_TRAIN:\", y_train, \"y_TEST:\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
